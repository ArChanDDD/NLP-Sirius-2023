{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3.1\n",
        "\n",
        "Сейчас мы с вами поиграем с RNN, которая решает задачу генерации текста.\n",
        "\n",
        "Ваша задача - поиграть с параметрами, и попробовать сделать так, чтобы ошибка модели была по крайней мере не больше 0.5"
      ],
      "metadata": {
        "id": "_JGSSZqme30s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "id": "VlUL48yYjc9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорты и функции"
      ],
      "metadata": {
        "id": "COVkvLnUfWBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from livelossplot import PlotLossesKeras\n",
        "import random\n",
        "import sys"
      ],
      "metadata": {
        "id": "54Qk4ZokgJoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "1hi_lDbbVuNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка и предобработка датасета"
      ],
      "metadata": {
        "id": "vf9gOCHzfc9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6BFrdDrUm6m"
      },
      "outputs": [],
      "source": [
        "with open('garri-potter.txt', 'r') as file:\n",
        "    text = file.read().lower()\n",
        "print('text length', len(text))\n",
        "\n",
        "chars = sorted(list(set(text))) # getting all unique chars\n",
        "print('total chars: ', len(chars))\n",
        "\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "metadata": {
        "id": "jnbr7YGdVUDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Построение модели"
      ],
      "metadata": {
        "id": "evHqa3ZkfhPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(maxlen, len(chars))))            # Это можно подбирать\n",
        "model.add(Dropout(0.2))                                           # Это можно подбирать\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.002)                          # Это можно подбирать\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "id": "PJbcN5t1VmXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=1, min_lr=0.0001)          # Это можно подбирать\n",
        "\n",
        "callbacks = [reduce_lr, PlotLossesKeras()]"
      ],
      "metadata": {
        "id": "0-MMO5QnWGMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение"
      ],
      "metadata": {
        "id": "73pZQAV4fjep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=128, epochs=10, callbacks=callbacks)   # Это можно подбирать"
      ],
      "metadata": {
        "id": "uVKl0aOWWItG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Генерация текста"
      ],
      "metadata": {
        "id": "jB8T9v8Yfu9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentence(sentence, diversity = 1.2):\n",
        "  generated = ''\n",
        "  generated += sentence\n",
        "  sentence = sentence[-maxlen:]\n",
        "  sys.stdout.write(generated)\n",
        "\n",
        "  for i in range(400):\n",
        "      x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "      for t, char in enumerate(sentence):\n",
        "          x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "      preds = model.predict(x_pred, verbose=0)[0]\n",
        "      next_index = sample(preds, diversity)\n",
        "      next_char = indices_char[next_index]\n",
        "\n",
        "      generated += next_char\n",
        "      sentence = sentence[1:] + next_char\n",
        "\n",
        "      sys.stdout.write(next_char)\n",
        "      sys.stdout.flush()\n",
        "  return generated"
      ],
      "metadata": {
        "id": "fsr9knOVWKcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = generate_sentence('гарри, рон, и гермиона зашли в комнату. там сидел драко и ехидно смотрел в стену. троица не растерялась и жестко отчислилась.')"
      ],
      "metadata": {
        "id": "Oxu9kbOSfGdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qR7LWFXGEO2T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}