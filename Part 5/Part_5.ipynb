{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5\n",
        "\n",
        "Это последнее занятие в курсе, и сегодня мы наконец поставим точку. Мы создадим своего бота!"
      ],
      "metadata": {
        "id": "wOZ37r2rfc4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyTelegramBotAPI\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "bn_m71LhgVWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Модель\n",
        "\n",
        "За основу мы возьмем модель `RuGPT3` - модель от Сбера, которая может генерировать сообщения.\n",
        "\n",
        "В теории, можно использовать и другие модели - их можно найти на [huggingface](https://huggingface.co/models) - важно правильно воспользоваться фильтрами, а то велика вероятность скачать что-то не то)\n",
        "\n",
        "Тут потребуется включенная в колабе GPU - для этого тыкаем сверху `Среда выполнения (Runtime)` → `Сменить среду выполнения (change runtime)` → выбираем GPU → нажимаем `Сохранить`"
      ],
      "metadata": {
        "id": "yEMYcBlMqBce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\").cuda()"
      ],
      "metadata": {
        "id": "pe5kOyjLqC1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функция предсказания\n",
        "\n",
        "Эта функция возвращает сгенерированный моделью текст"
      ],
      "metadata": {
        "id": "dho-sI6a1jZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# beam search\n",
        "\n",
        "def generate_text(text, max_letters):\n",
        "  ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0).cuda()\n",
        "  generated_ids = model.generate(\n",
        "                          input_ids=ids,  # input\n",
        "                          max_length=max_letters,  # default 20\n",
        "                          min_length=0,  # default 0\n",
        "                          do_sample=True,  # don't use greedy decoding\n",
        "                          early_stopping=False,  # search is stopped when at least num_beams sentences finished\n",
        "                          temperature=2.45,  # default 1.0\n",
        "                          top_k=45,  # default 50\n",
        "                          top_p=0.7,  # default 1.0\n",
        "                          repetition_penalty=2.0,  # rep. penalty\n",
        "                          num_beams=6,\n",
        "                          num_return_sequences=1, #  num ind. computed returned sequences\n",
        "                          bos_token_id=tokenizer.bos_token_id\n",
        "                          )\n",
        "  result = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "yxfkEBYHqGQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text('Однажды мы с друзьями пришли на пару по NLP.', 200).replace('<s>', ''), '\\n')"
      ],
      "metadata": {
        "id": "JZQR81BUqiM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прикольно, не правда ли?"
      ],
      "metadata": {
        "id": "9iiqDeq199q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Бот\n",
        "\n",
        "Для кого-то это будет открытием, но на питоне можно писать телеграм ботов! Причем делается это довольно несложно. Если появится желание создать бота с нуля - почитайте [несложную статейку в хабре](https://habr.com/ru/post/580408/)"
      ],
      "metadata": {
        "id": "_TrVHo5t1mal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если вы хотите его запустить - придется его создать :)\n",
        "\n",
        "Для этого делаем следущее:\n",
        "\n",
        "\n",
        "\n",
        "1.   Переходим на https://t.me/BotFather\n",
        "2.   Пишем там `/newbot`\n",
        "3.   Пишем для него имя (оно будет отображаться)\n",
        "4.   Пишем для него ник (он должен заканчиваться на `bot`)\n",
        "5.   Бот пришлет какую-то информацию и ваш **токен** - сохраняем его, и вставляем ниже\n",
        "\n"
      ],
      "metadata": {
        "id": "USYUXGpx-Uut"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bZaYfRAfCXm"
      },
      "outputs": [],
      "source": [
        "import telebot\n",
        "\n",
        "API_TOKEN = ... # Вот сюда надо поставить ваш токен в формате 'буквабуквацифрабуква'\n",
        "\n",
        "MAX_LEN = 75\n",
        "\n",
        "last_generated = ''\n",
        "\n",
        "bot = telebot.TeleBot(API_TOKEN)\n",
        "\n",
        "@bot.message_handler(commands=['start'])\n",
        "def start(message):\n",
        "    bot.send_message(message.chat.id, 'Привет! Отправляй мне начало историй, а я буду их продолжать :)')\n",
        "    bot.send_message(message.chat.id, 'Сейчас максимальная длина рассказа - ' + str(MAX_LEN) + ' букв, но ты можешь сделать ее больше командами!')\n",
        "\n",
        "@bot.message_handler(commands=['increase_len'])\n",
        "def increase_len(message):\n",
        "  global MAX_LEN\n",
        "  if MAX_LEN < 200:\n",
        "    MAX_LEN += 25\n",
        "    bot.send_message(message.chat.id, 'Увеличил максимальное количество букв до {}'.format(MAX_LEN))\n",
        "  else:\n",
        "    bot.send_message(message.chat.id, 'Уже и так много :(')\n",
        "\n",
        "@bot.message_handler(commands=['decrease_len'])\n",
        "def decrease_len(message):\n",
        "  global MAX_LEN\n",
        "  if MAX_LEN > 25:\n",
        "    MAX_LEN -= 25\n",
        "    bot.send_message(message.chat.id, 'Уменьшил максимальное количество букв до {}'.format(MAX_LEN))\n",
        "  else:\n",
        "    bot.send_message(message.chat.id, 'Куда меньше то? :(')\n",
        "\n",
        "@bot.message_handler(commands=['continue'])\n",
        "def continue_text(message):\n",
        "  global last_generated\n",
        "  generated_story = generate_text(last_generated, len(last_generated) + MAX_LEN).split('<s>')[0]\n",
        "  last_generated = generated_story \n",
        "\n",
        "  bot.send_message(message.chat.id, generated_story)\n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def generate_story(message):\n",
        "  global last_generated\n",
        "  generated_story = generate_text(message.text, min(MAX_LEN, len(message.text))).split('<s>')[0]\n",
        "  last_generated = generated_story\n",
        "\n",
        "  bot.send_message(message.chat.id, generated_story)\n",
        "\n",
        "while True:\n",
        "    bot.polling(none_stop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aijVUsB-gRfI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}